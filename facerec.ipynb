{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"facerec.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7qO0LTrC1nFX","colab_type":"text"},"source":["# Packages Section"]},{"cell_type":"code","metadata":{"id":"NPpw-FHKaKNS","colab_type":"code","outputId":"6be4b955-ed56-4adf-9b51-f58233776929","executionInfo":{"status":"ok","timestamp":1572390079818,"user_tz":-60,"elapsed":3009,"user":{"displayName":"Akinwande Gbenga","photoUrl":"","userId":"12180882598684964422"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Link to my google drive and change directory to current directory\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/My Drive/machine learning folder/IT Project')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WNYUXXe6aFaV","colab_type":"code","colab":{}},"source":[" #importing manipulations of data\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import accuracy_score,confusion_matrix,recall_score,precision_score,f1_score,roc_curve,roc_auc_score\n","\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","#Model Act manipulation\n","import torch\n","import torch as tch\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn, optim\n","import torch.nn.functional as F\n","from collections import OrderedDict\n","from PIL import  Image\n","import helper"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1yGxO_5tbhe8","colab_type":"text"},"source":["# Data Section"]},{"cell_type":"code","metadata":{"id":"UtytMLjun6q2","colab_type":"code","colab":{}},"source":["class Dataloader(Dataset):\n","\n","  #initialize the dataloader instance\n","  def __init__(self, X,y,train=True):\n","    self.X, self.y = X,y\n","\n","    if train:\n","      self.trans = transforms.Compose([ transforms.Resize((224,224)),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize([0.485, 0.456, 0.406],\n","                                                             [0.229, 0.224, 0.225])])\n","    else:\n","      self.trans = transforms.Compose([ transforms.Resize((224,224)),\n","                                        transforms.ToTensor()])\n","\n","    #one hotendcode target\n","    self.encod = OneHotEncoder(categories='auto',sparse=False)\n","    self.encod.fit(np.array([[0],[1]]))\n","\n","  def __getitem__(self, idx):\n","    #check if last sample \n","    if idx == (self.__len__()):\n","      raise StopIteration\n","      \n","    x_,y_ = self.X[idx], self.y[idx]\n","    trans = self.trans\n","\n","    #open images and resize\n","    img = Image.open(x_[0])\n","    img = trans(img).numpy().transpose((1, 2, 0))\n","\n","    img2 = Image.open(x_[1])\n","    img2 = trans(img2).numpy().transpose((1, 2, 0))\n","    \n","    #one hot encode target\n","    out = np.array([y_]) #output\n","    out = self.encod.transform(out)\n","\n","    #concate images together as flatten\n","    con_img = np.expand_dims(np.c_[img,img2],0)\n","    img_d = np.copy(con_img.transpose((0, 3, 1, 2)))  \n","\n","    img_d = tch.tensor(img_d.squeeze(0).astype('float32'))\n","    target = tch.tensor(out.squeeze(0).astype('float32'))\n","\n","    \n","    return img_d, target\n","\n","  def __len__(self):\n","    return len(self.X)\n","\n","\n","  #class method to initialize test and train class instances\n","  @classmethod\n","  def pre_pro_dset(cls, prt_fol_pth=\"Pictures\"):\n","\n","      dset = cls.fold_to_reldset(prt_fol_pth = prt_fol_pth)\n","      x_trn, y_trn, x_val, y_val, x_tst, y_tst = cls.shuffle_reldset(rel_dset=dset, split_d=True)\n","\n","      return cls(x_trn, y_trn,train=True), cls(x_val, y_val,train=False), cls(x_tst, y_tst,train=False)\n","\n","  #static method to create reference to the images \n","  @staticmethod\n","  def fold_to_reldset(prt_fol_pth = None):\n","      prt_fol = os.listdir(prt_fol_pth)\n","      nw_dset = np.empty((0,3))\n","\n","      #for each folder in the dataset\n","      for ech_samp in prt_fol:\n","        #for each picture in a folder\n","        for samp1 in os.listdir(os.path.join(prt_fol_pth, ech_samp)):\n","          #for pictures in a folder label as 1\n","          for samp2 in os.listdir(os.path.join(prt_fol_pth, ech_samp)): \n","            \n","            #create reference to images\n","            img = np.array(os.path.join(prt_fol_pth, ech_samp, samp1))\n","            img2 = np.array(os.path.join(prt_fol_pth, ech_samp, samp2))\n","\n","            #concate reference to images together\n","            out = np.array([1]) #output\n","            con_img = np.c_[img,img2]\n","            img_d = np.copy(np.c_[con_img,out])\n","\n","            #add img to dataset\n","            nw_dset = np.r_[nw_dset,img_d]   \n","\n","            #over sample the dataset, by adding the same instance\n","            nw_dset = np.r_[nw_dset,img_d]   \n","\n","          #for selecting different folder to label as 0\n","          for samp3 in prt_fol:\n","            #if current folder is selected ---> skip\n","            if samp3 == ech_samp:\n","              continue\n","            #if current folder is not the one initially selected\n","            else:\n","              #select pictures in the newly selected folder\n","              for samp4 in os.listdir(os.path.join(prt_fol_pth, samp3)):\n","                #open images and resize\n","                img = np.array(os.path.join(prt_fol_pth, ech_samp, samp1))\n","                img2 = np.array(os.path.join(prt_fol_pth, samp3, samp4))\n","\n","                #concate images together as flatten\n","                out = np.array([0]) #output\n","                con_img = np.c_[img,img2]\n","                img_d = np.copy(np.c_[con_img,out])\n","\n","                #add img to dataset\n","                nw_dset = np.r_[nw_dset,img_d] \n","\n","      return nw_dset\n","\n","  #static methos to shuffle the reference to the images and split then\n","  @staticmethod\n","  def shuffle_reldset(rel_dset=None,X=None,y=None,split_d=True,test_s=0.2):\n","    #splitting dataset into train,remaining\n","    np.random.seed(42)\n","    #try:\n","    if str(type(rel_dset)) == \"<class 'numpy.ndarray'>\":\n","      X = rel_dset[:,:-1]\n","      y = np.float32(rel_dset[:,-1:])\n","    \n","  #except:\n","    try:\n","        split = StratifiedShuffleSplit(test_size=test_s)\n","        for trn_idx, tst_idx in split.split(X,y):\n","            x_trn, x_tst = X[trn_idx], X[tst_idx]\n","            y_trn, y_tst = y[trn_idx], y[tst_idx]\n","\n","        if split_d == True:\n","          split = StratifiedShuffleSplit(test_size=0.5)\n","\n","          for trn_idx, tst_idx in split.split(x_tst,y_tst):\n","              x_val_, x_tst_ = X[trn_idx], X[tst_idx]\n","              y_val_, y_tst_ = y[trn_idx], y[tst_idx]\n","\n","          return (x_trn, y_trn, x_val_, y_val_, x_tst_, y_tst_) \n","        else:\n","          return (np.r_[x_trn,x_tst], np.r_[y_trn,y_tst])\n","\n","    except:\n","      print('x and y is NONE')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iyQVjb6lbVN5","colab_type":"text"},"source":["# Train Section"]},{"cell_type":"code","metadata":{"id":"Wa1D3w4DXQV8","colab_type":"code","colab":{}},"source":["#initialize the train and test data instance\n","train, val, test = Dataloader.pre_pro_dset()\n","train_loader = DataLoader( train, batch_size=32, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val, batch_size=32, shuffle=True, num_workers=2)\n","tst_loader = DataLoader(test, batch_size=32, shuffle=True, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xrIESm4nJXOT","colab_type":"code","colab":{}},"source":["#download model\n","squeeze = models.squeezenet1_1(pretrained=True)\n","\n","model = squeeze\n","\n","#change input to cnn\n","model.features[0] = nn.Conv2d(6, 64, kernel_size=(3, 3), stride=(2, 2))\n","\n","#change input to fc\n","model.classifier[1] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n","                                                \n","model = nn.Sequential(OrderedDict([('model', model),\n","                                   ('softmax_out',nn.Softmax(dim=1))]))\n","\n","#set parameters to require gradient\n","for param in model.parameters():\n","  if (ct >= 1 and ct <= 2) or (ct >= 50):\n","    param.requires_grad = True\n","  else:\n","    param.requires_grad = False\n","  ct += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xLCgpU_r6HV","colab_type":"code","colab":{}},"source":["squeeze = tch.load('model_gen1.pt')\n","\n","model = squeeze['model_arc']\n","model.load_state_dict(squeeze['state_dict'])\n","\n","ct = 1\n","\n","for param in model.parameters():\n","  if (ct >= 1 and ct <= 2) or (ct >= 50):\n","    param.requires_grad = True\n","  else:\n","    param.requires_grad = False\n","  ct += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1xZBn8uvYxo","colab_type":"code","outputId":"d16f3cf6-7ac8-4da6-8b25-f260019008b3","executionInfo":{"status":"ok","timestamp":1572380803388,"user_tz":-60,"elapsed":4198,"user":{"displayName":"Akinwande Gbenga","photoUrl":"","userId":"12180882598684964422"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["int(len(val_loader.dataset)/32)*32"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3264"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"zDYg7zW23J5t","colab_type":"code","colab":{}},"source":["#loss and optimizer\n","criterion = nn.BCELoss()\n","optimizer1 = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_L2mS5jE3J3C","colab_type":"code","colab":{}},"source":["class train_model:\n","  \n","  def __init__(self,model = None):\n","    self.model = model\n","    self.criterion = None\n","    self.optimizer = None\n","    self.weights = None\n","    self.t_epch = 0\n","    self.loaded_tr = 0\n","    self.loaded_vl = 0\n","    self.train_loss    = []\n","    self.test_loss     = []\n","    self.train_acc     = []\n","    self.train_pre     = []\n","    self.train_rec     = []\n","    self.train_f1_scr  = []\n","    self.test_acc      = []\n","    self.test_pre      = []\n","    self.test_rec      = []\n","    self.test_f1_scr   = []\n","    \n","  def train(self,train_loader=None, valid_loader=None,criterion=None,optimizer=None,epochs=5,batch_size=[32,32],lst_val_scr=0):\n","    \n","    model = self.model\n","    valid_rec_min = lst_val_scr\n","    train_on_gpu = tch.cuda.is_available()\n","    self.t_epch += epochs\n","\n","    if len(batch_size) == 2:\n","      batch_s_t = batch_size[0]\n","      batch_s_v = batch_size[1]\n","    else:\n","      batch_s_t = batch_size[0]\n","      batch_s_v = batch_size[0]    \n","\n","    for epoch in range(epochs):\n","      # keep track of training and validation loss and scores\n","\n","        train_loss    = 0.0\n","        test_loss     = 0.0\n","        train_acc     = 0.0\n","        train_pre     = 0.0\n","        train_rec     = 0.0\n","        train_f1_scr  = 0.0\n","        test_acc      = 0.0\n","        test_pre      = 0.0\n","        test_rec      = 0.0\n","        test_f1_scr   = 0.0\n","      \n","      ###################\n","      # train the model #\n","      ###################\n","        for data, target in train_loader:\n","            self.loaded_tr += len(data)\n","       \n","          # move tensors to GPU if CUDA is available\n","            if train_on_gpu: \n","                model.cuda()\n","                model.train()\n","                data, target = data.cuda(), target.cuda()\n","            else:\n","                model.cpu()\n","                model.train()\n","                data, target = data.cpu(), target.cpu()\n","     \n","          # clear the gradients of all optimized variables\n","            optimizer.zero_grad()\n","     \n","            print(f'in Train-->({self.loaded_tr}) \\n')          \n","          \n","          \n","          # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(data)\n","            #print(f'output_train is {output} and target is {target}')\n","          # calculate the batch loss\n","            loss = criterion(output, target)                   \n","      \n","          # backward pass: compute gradient of the loss with respect to model parameters\n","            loss.backward()\n","      \n","          # perform a single optimization step (parameter update)\n","            optimizer.step()\n","       \n","          # update training loss\n","            train_loss     +=  loss.item()\n","            train_acc      +=  accuracy_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            train_pre      +=  precision_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            train_rec      +=  recall_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            train_f1_scr   +=  f1_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            self.save_model()\n","        self.loaded_tr = 0\n","\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","        model.eval()\n","     \n","        for data, target in valid_loader:\n","            self.loaded_vl += len(data)\n","\n","            # move tensors to GPU if CUDA is available\n","            if train_on_gpu: \n","                model.cuda()\n","                model.train()\n","                data, target = data.cuda(), target.cuda()\n","            else:\n","                model.cpu()\n","                model.train()\n","                data, target = data.cpu(), target.cpu()\n","\n","            print(f'in val-->({self.loaded_vl}) \\n ')\n","                \n","          # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(data)\n","            #print(f'output_val is {output} and target is {target}')\n","          # calculate the batch loss\n","            loss = criterion(output, target)\n","                    \n","          # update average validation loss \n","            test_loss     += loss.item()\n","            test_acc       += accuracy_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            test_pre       += precision_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            test_rec       +=  recall_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            test_f1_scr    +=  f1_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            \n","        self.loaded_vl = 0      \n","\n","      # calculate average losses and scores\n","        train_loss = train_loss/round(len(train_loader.dataset)/batch_s_t)\n","        test_loss = test_loss/round(len(valid_loader.dataset)/batch_s_v)\n","      \n","        train_acc       =   1 if  train_acc/round(len(train_loader.dataset)/batch_s_t) > 1 else train_acc/round(len(train_loader.dataset)/batch_s_t)\n","\n","        train_pre       =   1 if train_pre/round(len(train_loader.dataset)/batch_s_t) > 1 else train_pre/round(len(train_loader.dataset)/batch_s_t)\n","\n","        train_rec       =   1 if train_rec/round(len(train_loader.dataset)/batch_s_t) > 1 else train_rec/round(len(train_loader.dataset)/batch_s_t)\n","                                     \n","        train_f1_scr    =   1 if train_f1_scr/round(len(train_loader.dataset)/batch_s_t) > 1 else train_f1_scr/round(len(train_loader.dataset)/batch_s_t)\n","\n","        test_acc        =   1 if test_acc/round(len(valid_loader.dataset)/batch_s_v) > 1 else test_acc/round(len(valid_loader.dataset)/batch_s_v)\n","\n","        test_pre        =   1 if test_pre/round(len(valid_loader.dataset)/batch_s_v) > 1 else test_pre/round(len(valid_loader.dataset)/batch_s_v)\n","  \n","        test_rec        =   1 if test_rec/round(len(valid_loader.dataset)/batch_s_v,5) > 1 else test_rec/round(len(valid_loader.dataset)/batch_s_v,5)\n","\n","        test_f1_scr    =   1 if test_f1_scr/round(len(valid_loader.dataset)/batch_s_v,5) > 1 else test_f1_scr/round(len(valid_loader.dataset)/batch_s_v,5) \n","\n","      \n","\n","            \n","      #append train scores\n","        self.train_loss.append(train_loss)\n","        self.train_acc.append(train_acc)\n","        self.train_rec.append(train_rec)\n","        self.train_f1_scr.append(train_f1_scr)\n","        self.train_pre.append(train_pre)\n","        \n","      #append test scores\n","        self.test_loss.append(test_loss)\n","        self.test_acc.append(test_acc)\n","        self.test_rec.append(test_rec)\n","        self.test_f1_scr.append(test_f1_scr)\n","        self.test_pre.append(test_pre)\n","        \n","      # print training/validation statistics \n","        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} '.format(epoch, train_loss, test_loss))\n","      \n","        print('train Accuracy score : {:.6f} \\ttrain Precision Score: {:.6f} \\ttrain Recall Score: {:.6f}\\ttrain f1 Score: {:.6f}'.format(train_acc, train_pre, train_rec, train_f1_scr))\n","      \n","        print('test Accuracy score : {:.6f} \\ttest Precision Score: {:.6f} \\ttest Recall Score: {:.6f}\\ttest f1 Score: {:.6f}'.format(test_acc, test_pre, test_rec, test_f1_scr))\n","\n","        # save model if validation loss has decreased\n","        if test_rec > valid_rec_min:\n","            print('test recall increased ({:.6f} --> {:.6f}).  Saving model ...\\n\\n'.format(valid_rec_min,test_rec))\n","            \n","            #Save State_dict\n","            model_info = {'model_arc'  : model,\n","                             'state_dict' : model.state_dict(),\n","                              'val_recall' : test_rec}\n","            \n","\n","            torch.save(model_info, 'model_deploy1.pt')\n","            valid_rec_min = test_rec\n","\n","  def predict(self,data):\n","    model = self.model\n","    model.cpu().eval()\n","    \n","    data = data.cpu()\n","\n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    output = model(data)\n","    \n","    return output.cpu().topk(1)[1].detach().numpy()\n","  \n","  \n","  def save_model(self):\n","    model = self.model\n","    \n","    #Save State_dict\n","    model_info = {'model_arc'  : model,\n","                      'state_dict' : model.state_dict()}\n","\n","    torch.save(model_info, 'model_gen1.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FYh0tZqfucWj","colab_type":"code","outputId":"a3ed5b98-1428-4644-d7af-66facfe50b95","executionInfo":{"status":"ok","timestamp":1572240894662,"user_tz":-60,"elapsed":1206054,"user":{"displayName":"Akinwande Gbenga","photoUrl":"","userId":"12180882598684964422"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = train_model(model=model)\n","model.train(train_loader=train_loader,valid_loader=val_loader,criterion=criterion,optimizer=optimizer1,epochs=5,batch_size=[32,32],lst_val_scr=0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["in Train-->(32) \n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SqueezeNet. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Fire. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Softmax. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"},{"output_type":"stream","text":["in Train-->(64) \n","\n","in Train-->(96) \n","\n","in Train-->(128) \n","\n","in Train-->(160) \n","\n","in Train-->(192) \n","\n","in Train-->(224) \n","\n","in Train-->(256) \n","\n","in Train-->(288) \n","\n","in Train-->(320) \n","\n","in Train-->(352) \n","\n","in Train-->(384) \n","\n","in Train-->(416) \n","\n","in Train-->(448) \n","\n","in Train-->(480) \n","\n","in Train-->(512) \n","\n","in Train-->(544) \n","\n","in Train-->(576) \n","\n","in Train-->(608) \n","\n","in Train-->(640) \n","\n","in Train-->(672) \n","\n","in Train-->(704) \n","\n","in Train-->(736) \n","\n","in Train-->(768) \n","\n","in Train-->(800) \n","\n","in Train-->(832) \n","\n","in Train-->(864) \n","\n","in Train-->(896) \n","\n","in Train-->(928) \n","\n","in Train-->(960) \n","\n","in Train-->(992) \n","\n","in Train-->(1024) \n","\n","in Train-->(1056) \n","\n","in Train-->(1088) \n","\n","in Train-->(1120) \n","\n","in Train-->(1152) \n","\n","in Train-->(1184) \n","\n","in Train-->(1216) \n","\n","in Train-->(1248) \n","\n","in Train-->(1280) \n","\n","in Train-->(1312) \n","\n","in Train-->(1344) \n","\n","in Train-->(1376) \n","\n","in Train-->(1408) \n","\n","in Train-->(1440) \n","\n","in Train-->(1472) \n","\n","in Train-->(1504) \n","\n","in Train-->(1536) \n","\n","in Train-->(1568) \n","\n","in Train-->(1600) \n","\n","in Train-->(1632) \n","\n","in Train-->(1664) \n","\n","in Train-->(1696) \n","\n","in Train-->(1728) \n","\n","in Train-->(1760) \n","\n","in Train-->(1792) \n","\n","in Train-->(1824) \n","\n","in Train-->(1856) \n","\n","in Train-->(1888) \n","\n","in Train-->(1920) \n","\n","in Train-->(1952) \n","\n","in Train-->(1984) \n","\n","in Train-->(2016) \n","\n","in Train-->(2048) \n","\n","in Train-->(2080) \n","\n","in Train-->(2112) \n","\n","in Train-->(2144) \n","\n","in Train-->(2176) \n","\n","in Train-->(2208) \n","\n","in Train-->(2240) \n","\n","in Train-->(2272) \n","\n","in Train-->(2304) \n","\n","in Train-->(2336) \n","\n","in Train-->(2368) \n","\n","in Train-->(2400) \n","\n","in Train-->(2432) \n","\n","in Train-->(2464) \n","\n","in Train-->(2496) \n","\n","in Train-->(2528) \n","\n","in Train-->(2560) \n","\n","in Train-->(2592) \n","\n","in Train-->(2624) \n","\n","in Train-->(2656) \n","\n","in Train-->(2688) \n","\n","in Train-->(2720) \n","\n","in Train-->(2752) \n","\n","in Train-->(2784) \n","\n","in Train-->(2816) \n","\n","in Train-->(2848) \n","\n","in Train-->(2880) \n","\n","in Train-->(2912) \n","\n","in Train-->(2944) \n","\n","in Train-->(2976) \n","\n","in Train-->(3008) \n","\n","in Train-->(3040) \n","\n","in Train-->(3072) \n","\n","in Train-->(3104) \n","\n","in Train-->(3136) \n","\n","in Train-->(3168) \n","\n","in Train-->(3200) \n","\n","in Train-->(3232) \n","\n","in Train-->(3264) \n","\n","in Train-->(3296) \n","\n","in Train-->(3328) \n","\n","in Train-->(3360) \n","\n","in Train-->(3392) \n","\n","in Train-->(3424) \n","\n","in Train-->(3456) \n","\n","in Train-->(3488) \n","\n","in Train-->(3520) \n","\n","in Train-->(3552) \n","\n","in Train-->(3584) \n","\n","in Train-->(3616) \n","\n","in Train-->(3648) \n","\n","in Train-->(3680) \n","\n","in Train-->(3712) \n","\n","in Train-->(3744) \n","\n","in Train-->(3776) \n","\n","in Train-->(3808) \n","\n","in Train-->(3840) \n","\n","in Train-->(3872) \n","\n","in Train-->(3904) \n","\n","in Train-->(3936) \n","\n","in Train-->(3968) \n","\n","in Train-->(4000) \n","\n","in Train-->(4032) \n","\n","in Train-->(4064) \n","\n","in Train-->(4096) \n","\n","in Train-->(4128) \n","\n","in Train-->(4160) \n","\n","in Train-->(4192) \n","\n","in Train-->(4224) \n","\n","in Train-->(4256) \n","\n","in Train-->(4288) \n","\n","in Train-->(4320) \n","\n","in Train-->(4352) \n","\n","in Train-->(4384) \n","\n","in Train-->(4416) \n","\n","in Train-->(4448) \n","\n","in Train-->(4480) \n","\n","in Train-->(4512) \n","\n","in Train-->(4544) \n","\n","in Train-->(4576) \n","\n","in Train-->(4608) \n","\n","in Train-->(4640) \n","\n","in Train-->(4672) \n","\n","in Train-->(4704) \n","\n","in Train-->(4736) \n","\n","in Train-->(4768) \n","\n","in Train-->(4800) \n","\n","in Train-->(4832) \n","\n","in Train-->(4864) \n","\n","in Train-->(4896) \n","\n","in Train-->(4928) \n","\n","in Train-->(4960) \n","\n","in Train-->(4992) \n","\n","in Train-->(5024) \n","\n","in Train-->(5056) \n","\n","in Train-->(5088) \n","\n","in Train-->(5120) \n","\n","in Train-->(5152) \n","\n","in Train-->(5184) \n","\n","in Train-->(5216) \n","\n","in Train-->(5248) \n","\n","in Train-->(5280) \n","\n","in Train-->(5312) \n","\n","in Train-->(5344) \n","\n","in Train-->(5376) \n","\n","in Train-->(5408) \n","\n","in Train-->(5440) \n","\n","in Train-->(5472) \n","\n","in Train-->(5504) \n","\n","in Train-->(5536) \n","\n","in Train-->(5568) \n","\n","in Train-->(5600) \n","\n","in Train-->(5632) \n","\n","in Train-->(5664) \n","\n","in Train-->(5696) \n","\n","in Train-->(5728) \n","\n","in Train-->(5760) \n","\n","in Train-->(5792) \n","\n","in Train-->(5824) \n","\n","in Train-->(5856) \n","\n","in Train-->(5888) \n","\n","in Train-->(5920) \n","\n","in Train-->(5952) \n","\n","in Train-->(5984) \n","\n","in Train-->(6016) \n","\n","in Train-->(6048) \n","\n","in Train-->(6080) \n","\n","in Train-->(6112) \n","\n","in Train-->(6144) \n","\n","in Train-->(6176) \n","\n","in Train-->(6208) \n","\n","in Train-->(6240) \n","\n","in Train-->(6272) \n","\n","in Train-->(6304) \n","\n","in Train-->(6336) \n","\n","in Train-->(6368) \n","\n","in Train-->(6400) \n","\n","in Train-->(6432) \n","\n","in Train-->(6464) \n","\n","in Train-->(6496) \n","\n","in Train-->(6528) \n","\n","in Train-->(6560) \n","\n","in Train-->(6592) \n","\n","in Train-->(6624) \n","\n","in Train-->(6656) \n","\n","in Train-->(6688) \n","\n","in Train-->(6720) \n","\n","in Train-->(6752) \n","\n","in Train-->(6784) \n","\n","in Train-->(6816) \n","\n","in Train-->(6848) \n","\n","in Train-->(6880) \n","\n","in Train-->(6912) \n","\n","in Train-->(6944) \n","\n","in Train-->(6976) \n","\n","in Train-->(7008) \n","\n","in Train-->(7040) \n","\n","in Train-->(7072) \n","\n","in Train-->(7104) \n","\n","in Train-->(7136) \n","\n","in Train-->(7168) \n","\n","in Train-->(7200) \n","\n","in Train-->(7232) \n","\n","in Train-->(7264) \n","\n","in Train-->(7296) \n","\n","in Train-->(7328) \n","\n","in Train-->(7360) \n","\n","in Train-->(7392) \n","\n","in Train-->(7424) \n","\n","in Train-->(7456) \n","\n","in Train-->(7488) \n","\n","in Train-->(7520) \n","\n","in Train-->(7552) \n","\n","in Train-->(7584) \n","\n","in Train-->(7616) \n","\n","in Train-->(7648) \n","\n","in Train-->(7680) \n","\n","in Train-->(7712) \n","\n","in Train-->(7744) \n","\n","in Train-->(7776) \n","\n","in Train-->(7808) \n","\n","in Train-->(7840) \n","\n","in Train-->(7872) \n","\n","in Train-->(7904) \n","\n","in Train-->(7936) \n","\n","in Train-->(7968) \n","\n","in Train-->(8000) \n","\n","in Train-->(8032) \n","\n","in Train-->(8064) \n","\n","in Train-->(8096) \n","\n","in Train-->(8128) \n","\n","in Train-->(8160) \n","\n","in Train-->(8192) \n","\n","in Train-->(8224) \n","\n","in Train-->(8256) \n","\n","in Train-->(8288) \n","\n","in Train-->(8320) \n","\n","in Train-->(8352) \n","\n","in Train-->(8384) \n","\n","in Train-->(8416) \n","\n","in Train-->(8448) \n","\n","in Train-->(8480) \n","\n","in Train-->(8512) \n","\n","in Train-->(8544) \n","\n","in Train-->(8576) \n","\n","in Train-->(8608) \n","\n","in Train-->(8640) \n","\n","in Train-->(8672) \n","\n","in Train-->(8704) \n","\n","in Train-->(8736) \n","\n","in Train-->(8768) \n","\n","in Train-->(8800) \n","\n","in Train-->(8832) \n","\n","in Train-->(8864) \n","\n","in Train-->(8896) \n","\n","in Train-->(8928) \n","\n","in Train-->(8960) \n","\n","in Train-->(8992) \n","\n","in Train-->(9024) \n","\n","in Train-->(9056) \n","\n","in Train-->(9088) \n","\n","in Train-->(9120) \n","\n","in Train-->(9152) \n","\n","in Train-->(9184) \n","\n","in Train-->(9216) \n","\n","in Train-->(9248) \n","\n","in Train-->(9280) \n","\n","in Train-->(9312) \n","\n","in Train-->(9344) \n","\n","in Train-->(9376) \n","\n","in Train-->(9408) \n","\n","in Train-->(9440) \n","\n","in Train-->(9472) \n","\n","in Train-->(9504) \n","\n","in Train-->(9536) \n","\n","in Train-->(9568) \n","\n","in Train-->(9600) \n","\n","in Train-->(9632) \n","\n","in Train-->(9664) \n","\n","in Train-->(9696) \n","\n","in Train-->(9728) \n","\n","in Train-->(9760) \n","\n","in Train-->(9792) \n","\n","in Train-->(9824) \n","\n","in Train-->(9856) \n","\n","in Train-->(9888) \n","\n","in Train-->(9920) \n","\n","in Train-->(9952) \n","\n","in Train-->(9984) \n","\n","in Train-->(10016) \n","\n","in Train-->(10048) \n","\n","in Train-->(10080) \n","\n","in Train-->(10112) \n","\n","in Train-->(10144) \n","\n","in Train-->(10176) \n","\n","in Train-->(10208) \n","\n","in Train-->(10240) \n","\n","in Train-->(10272) \n","\n","in Train-->(10304) \n","\n","in Train-->(10336) \n","\n","in Train-->(10368) \n","\n","in Train-->(10400) \n","\n","in Train-->(10432) \n","\n","in Train-->(10464) \n","\n","in Train-->(10496) \n","\n","in Train-->(10528) \n","\n","in Train-->(10560) \n","\n","in Train-->(10592) \n","\n","in Train-->(10624) \n","\n","in Train-->(10656) \n","\n","in Train-->(10688) \n","\n","in Train-->(10720) \n","\n","in Train-->(10752) \n","\n","in Train-->(10784) \n","\n","in Train-->(10816) \n","\n","in Train-->(10848) \n","\n","in Train-->(10880) \n","\n","in Train-->(10912) \n","\n","in Train-->(10944) \n","\n","in Train-->(10976) \n","\n","in Train-->(11008) \n","\n","in Train-->(11040) \n","\n","in Train-->(11072) \n","\n","in Train-->(11104) \n","\n","in Train-->(11136) \n","\n","in Train-->(11168) \n","\n","in Train-->(11200) \n","\n","in Train-->(11232) \n","\n","in Train-->(11264) \n","\n","in Train-->(11296) \n","\n","in Train-->(11328) \n","\n","in Train-->(11360) \n","\n","in Train-->(11392) \n","\n","in Train-->(11424) \n","\n","in Train-->(11456) \n","\n","in Train-->(11488) \n","\n","in Train-->(11520) \n","\n","in Train-->(11552) \n","\n","in Train-->(11584) \n","\n","in Train-->(11616) \n","\n","in Train-->(11648) \n","\n","in Train-->(11680) \n","\n","in Train-->(11712) \n","\n","in Train-->(11744) \n","\n","in Train-->(11776) \n","\n","in Train-->(11808) \n","\n","in Train-->(11840) \n","\n","in Train-->(11872) \n","\n","in Train-->(11904) \n","\n","in Train-->(11936) \n","\n","in Train-->(11968) \n","\n","in Train-->(12000) \n","\n","in Train-->(12032) \n","\n","in Train-->(12064) \n","\n","in Train-->(12096) \n","\n","in Train-->(12128) \n","\n","in Train-->(12160) \n","\n","in Train-->(12192) \n","\n","in Train-->(12224) \n","\n","in Train-->(12256) \n","\n","in Train-->(12288) \n","\n","in Train-->(12320) \n","\n","in Train-->(12352) \n","\n","in Train-->(12384) \n","\n","in Train-->(12416) \n","\n","in Train-->(12448) \n","\n","in Train-->(12480) \n","\n","in Train-->(12512) \n","\n","in Train-->(12544) \n","\n","in Train-->(12576) \n","\n","in Train-->(12608) \n","\n","in Train-->(12640) \n","\n","in Train-->(12672) \n","\n","in Train-->(12704) \n","\n","in Train-->(12736) \n","\n","in Train-->(12768) \n","\n","in Train-->(12800) \n","\n","in Train-->(12832) \n","\n","in Train-->(12864) \n","\n","in Train-->(12896) \n","\n","in Train-->(12928) \n","\n","in Train-->(12960) \n","\n","in Train-->(12992) \n","\n","in Train-->(13024) \n","\n","in Train-->(13056) \n","\n","in Train-->(13088) \n","\n","in Train-->(13120) \n","\n","in Train-->(13152) \n","\n","in Train-->(13184) \n","\n","in Train-->(13216) \n","\n","in Train-->(13248) \n","\n","in Train-->(13280) \n","\n","in Train-->(13312) \n","\n","in Train-->(13344) \n","\n","in Train-->(13376) \n","\n","in Train-->(13408) \n","\n","in Train-->(13440) \n","\n","in Train-->(13472) \n","\n","in Train-->(13504) \n","\n","in Train-->(13536) \n","\n","in Train-->(13568) \n","\n","in Train-->(13600) \n","\n","in Train-->(13632) \n","\n","in Train-->(13664) \n","\n","in Train-->(13696) \n","\n","in Train-->(13728) \n","\n","in Train-->(13760) \n","\n","in Train-->(13792) \n","\n","in Train-->(13824) \n","\n","in Train-->(13856) \n","\n","in Train-->(13888) \n","\n","in Train-->(13920) \n","\n","in Train-->(13952) \n","\n","in Train-->(13984) \n","\n","in Train-->(14016) \n","\n","in Train-->(14048) \n","\n","in Train-->(14080) \n","\n","in Train-->(14112) \n","\n","in Train-->(14144) \n","\n","in Train-->(14176) \n","\n","in Train-->(14208) \n","\n","in Train-->(14240) \n","\n","in Train-->(14272) \n","\n","in Train-->(14304) \n","\n","in Train-->(14336) \n","\n","in Train-->(14368) \n","\n","in Train-->(14400) \n","\n","in Train-->(14432) \n","\n","in Train-->(14464) \n","\n","in Train-->(14496) \n","\n","in Train-->(14528) \n","\n","in Train-->(14560) \n","\n","in Train-->(14592) \n","\n","in Train-->(14624) \n","\n","in Train-->(14656) \n","\n","in Train-->(14688) \n","\n","in Train-->(14720) \n","\n","in Train-->(14752) \n","\n","in Train-->(14784) \n","\n","in Train-->(14816) \n","\n","in Train-->(14848) \n","\n","in Train-->(14880) \n","\n","in Train-->(14912) \n","\n","in Train-->(14944) \n","\n","in Train-->(14976) \n","\n","in Train-->(15008) \n","\n","in Train-->(15040) \n","\n","in Train-->(15072) \n","\n","in Train-->(15104) \n","\n","in Train-->(15136) \n","\n","in Train-->(15168) \n","\n","in Train-->(15200) \n","\n","in Train-->(15232) \n","\n","in Train-->(15264) \n","\n","in Train-->(15296) \n","\n","in Train-->(15328) \n","\n","in Train-->(15360) \n","\n","in Train-->(15392) \n","\n","in Train-->(15424) \n","\n","in Train-->(15456) \n","\n","in Train-->(15488) \n","\n","in Train-->(15520) \n","\n","in Train-->(15552) \n","\n","in Train-->(15584) \n","\n","in Train-->(15616) \n","\n","in Train-->(15648) \n","\n","in Train-->(15680) \n","\n","in Train-->(15712) \n","\n","in Train-->(15744) \n","\n","in Train-->(15776) \n","\n","in Train-->(15808) \n","\n","in Train-->(15840) \n","\n","in Train-->(15872) \n","\n","in Train-->(15904) \n","\n","in Train-->(15936) \n","\n","in Train-->(15968) \n","\n","in Train-->(16000) \n","\n","in Train-->(16032) \n","\n","in Train-->(16064) \n","\n","in Train-->(16096) \n","\n","in Train-->(16128) \n","\n","in Train-->(16160) \n","\n","in Train-->(16192) \n","\n","in Train-->(16224) \n","\n","in Train-->(16256) \n","\n","in Train-->(16288) \n","\n","in Train-->(16320) \n","\n","in Train-->(16352) \n","\n","in Train-->(16384) \n","\n","in Train-->(16416) \n","\n","in Train-->(16448) \n","\n","in Train-->(16480) \n","\n","in Train-->(16512) \n","\n","in Train-->(16544) \n","\n","in Train-->(16576) \n","\n","in Train-->(16608) \n","\n","in Train-->(16640) \n","\n","in Train-->(16672) \n","\n","in Train-->(16704) \n","\n","in Train-->(16736) \n","\n","in Train-->(16768) \n","\n","in Train-->(16800) \n","\n","in Train-->(16832) \n","\n","in Train-->(16864) \n","\n","in Train-->(16896) \n","\n","in Train-->(16928) \n","\n","in Train-->(16960) \n","\n","in Train-->(16992) \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QPkVDwcrBFeK","colab_type":"code","colab":{}},"source":["#testing modelb\n","mod = tch.load('fcmodel_train.pt')\n","fc = mod['model_arc']\n","fc.load_state_dict(mod['state_dict'])\n","\n","resnet = torch.load('cnnmodel_train.pt')\n","cnn = resnet['model_arc']\n","cnn.load_state_dict(resnet['state_dict'])\n","\n","#model\n","model = train_model(cnn=cnn, model=fc)\n","\n","#data\n","data_x = np.load('features.npy')\n","data_y  = np.load('targets.npy')\n","\n","#data to tensor data\n","data_x = tch.tensor(data_x.astype(np.float32))\n","data_y = tch.tensor(data_y.astype(np.float32)) \n","\n","#predict accuracy\n","# accuracy_score(model.predict(data_x[:50,:,:,:]).numpy(),data_y[:50])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KjIh35rh0iMd","colab_type":"code","outputId":"a331026a-56ce-4eb1-f74e-af4b93ab6d5a","executionInfo":{"status":"ok","timestamp":1572174929540,"user_tz":-60,"elapsed":1967,"user":{"displayName":"Akinwande Gbenga","photoUrl":"","userId":"12180882598684964422"}},"colab":{"base_uri":"https://localhost:8080/","height":411}},"source":["model.save_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Softmax. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Bottleneck. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Identity. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"8xKqT9QR0nWb","colab_type":"text"},"source":["# reserved codes"]},{"cell_type":"code","metadata":{"id":"zubYmre44f2s","colab_type":"code","colab":{}},"source":["# # img = np.copy(np.ones((1, 301056)))\n","# # img2 = np.copy(np.zeros((1, 301056)))\n","# img = (plt.imread('Pictures/fes/DSC_0269.JPG')/225 - [0.485, 0.456, 0.406])/[0.229, 0.224, 0.225]\n","# img2 = plt.imread('Pictures/blaq/IMG_20190428_004049.jpg')\n","# # np.c_[img,img2].shape\n","# plt.imshow(img)\n","# # img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3SBgTcNvcWO","colab_type":"code","colab":{}},"source":["# #function to load dataset\n","# def fold_to_datast(prt_fol_pth = 'Pictures'):\n","#   siz = 224\n","#   prt_fol = os.listdir(prt_fol_pth)\n","#   nw_dset = np.empty((0,224,224,6))\n","#   target = np.empty((0,1))\n","#   trans = transforms.Compose([ transforms.Resize((224,224)),\n","#                                       transforms.ToTensor(),\n","#                                       transforms.Normalize([0.485, 0.456, 0.406],\n","#                                                            [0.229, 0.224, 0.225])])\n","\n","#   #for each folder in the dataset\n","#   for ech_samp in prt_fol:\n","\n","#     #for each picture in a folder\n","#     for samp1 in os.listdir(os.path.join(prt_fol_pth, ech_samp)):\n","\n","#       #for pictures in a folder label as 1\n","#       for samp2 in os.listdir(os.path.join(prt_fol_pth, ech_samp)):\n","        \n","#         #open images and resize\n","#         img = Image.open(os.path.join(prt_fol_pth, ech_samp, samp1))\n","#         img = trans(img).numpy().transpose((1, 2, 0))\n","\n","#         img2 = Image.open(os.path.join(prt_fol_pth, ech_samp, samp2))\n","#         img2 = trans(img2).numpy().transpose((1, 2, 0))\n","        \n","#         #concate images together as flatten\n","#         out = np.array([[1]]) #output\n","#         con_img = np.expand_dims(np.c_[img,img2],0)\n","# #         img_d = np.copy(np.c_[con_img,out])\n","#         img_d = np.copy(con_img)\n","\n","#         #add img to dataset\n","# #         print(f'shape = {img_d.shape}')\n","#         nw_dset = np.r_[nw_dset,img_d]\n","#         target = np.r_[target,out]\n","                          \n","# #         print(f'{ech_samp+samp1} and {ech_samp+samp2} is {1}')\n","\n","#       #for selecting different folder to label as 0\n","#       for samp3 in prt_fol:\n","\n","#         #if current folder is selected ---> skip\n","#         if samp3 == ech_samp:\n","#           continue\n","\n","#         #if current folder is not the one initially selected\n","#         else:\n","#           #select pictures in the newly selected folder\n","#           for samp4 in os.listdir(os.path.join(prt_fol_pth, samp3)):\n","            \n","#             #open images and resize\n","#             img = Image.open(os.path.join(prt_fol_pth, ech_samp, samp1))\n","#             img = trans(img).numpy().transpose((1, 2, 0))\n","            \n","#             img2 = Image.open(os.path.join(prt_fol_pth, samp3, samp4))\n","#             img2 = trans(img2).numpy().transpose((1, 2, 0))\n","             \n","#             #concate images together as flatten\n","#             out = np.array([[0]]) #output\n","#             con_img = np.expand_dims(np.c_[img,img2],0)\n","#             img_d = np.copy(con_img)\n","#             nw_dset = np.r_[nw_dset,img_d]\n","#             target = np.r_[target,out]\n","# #             print(f'{ech_samp+samp1} and {samp3+samp4} is {0}')\n","\n","#   return nw_dset,target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xcHTwjj9wf-","colab_type":"code","colab":{}},"source":["# def fold_to_datast(prt_fol_pth = 'Pictures'):\n","#   prt_fol = os.listdir(prt_fol_pth)\n","#   nw_dset = np.empty((0,3))\n","\n","#   #for each folder in the dataset\n","#   for ech_samp in prt_fol:\n","#     #for each picture in a folder\n","#     for samp1 in os.listdir(os.path.join(prt_fol_pth, ech_samp)):\n","#       #for pictures in a folder label as 1\n","#       for samp2 in os.listdir(os.path.join(prt_fol_pth, ech_samp)): \n","        \n","#         #open images and resize\n","#         img = np.array(os.path.join(prt_fol_pth, ech_samp, samp1))\n","#         img2 = np.array(os.path.join(prt_fol_pth, ech_samp, samp2))\n","\n","#         #concate images together as flatten\n","#         out = np.array([1]) #output\n","#         con_img = np.c_[img,img2]\n","#         img_d = np.copy(np.c_[con_img,out])\n","\n","#         #add img to dataset\n","#         nw_dset = np.r_[nw_dset,img_d]   \n","\n","#         #over sample the dataset, by adding the same instance\n","#         nw_dset = np.r_[nw_dset,img_d]   \n","\n","# #       #for selecting different folder to label as 0\n","#       for samp3 in prt_fol:\n","#         #if current folder is selected ---> skip\n","#         if samp3 == ech_samp:\n","#           continue\n","#         #if current folder is not the one initially selected\n","#         else:\n","#           #select pictures in the newly selected folder\n","#           for samp4 in os.listdir(os.path.join(prt_fol_pth, samp3)):\n","#             #open images and resize\n","#             img = np.array(os.path.join(prt_fol_pth, ech_samp, samp1))\n","#             img2 = np.array(os.path.join(prt_fol_pth, samp3, samp4))\n","\n","#             #concate images together as flatten\n","#             out = np.array([0]) #output\n","#             con_img = np.c_[img,img2]\n","#             img_d = np.copy(np.c_[con_img,out])\n","\n","#             #add img to dataset\n","#             nw_dset = np.r_[nw_dset,img_d]  \n","#   print(f'dset : {nw_dset.shape}')\n","#   return nw_dset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9El8f812iFNu","colab_type":"code","colab":{}},"source":["# class pre_pro_dset:\n","\n","#   def __init__(self, prt_fol_pth='Pictures'):\n","#       self.fold_to_reldset(prt_fol_pth = prt_fol_pth)\n","#       self.shuffle_reldset()\n","\n","#   def fold_to_reldset(self,prt_fol_pth = None):\n","#       prt_fol = os.listdir(prt_fol_pth)\n","#       nw_dset = np.empty((0,3))\n","\n","#       #for each folder in the dataset\n","#       for ech_samp in prt_fol:\n","#         #for each picture in a folder\n","#         for samp1 in os.listdir(os.path.join(prt_fol_pth, ech_samp)):\n","#           #for pictures in a folder label as 1\n","#           for samp2 in os.listdir(os.path.join(prt_fol_pth, ech_samp)): \n","            \n","#             #open images and resize\n","#             img = np.array(os.path.join(prt_fol_pth, ech_samp, samp1))\n","#             img2 = np.array(os.path.join(prt_fol_pth, ech_samp, samp2))\n","\n","#             #concate images together as flatten\n","#             out = np.array([1]) #output\n","#             con_img = np.c_[img,img2]\n","#             img_d = np.copy(np.c_[con_img,out])\n","\n","#             #add img to dataset\n","#             nw_dset = np.r_[nw_dset,img_d]   \n","\n","#             #over sample the dataset, by adding the same instance\n","#             nw_dset = np.r_[nw_dset,img_d]   \n","\n","#           #for selecting different folder to label as 0\n","#           for samp3 in prt_fol:\n","#             #if current folder is selected ---> skip\n","#             if samp3 == ech_samp:\n","#               continue\n","#             #if current folder is not the one initially selected\n","#             else:\n","#               #select pictures in the newly selected folder\n","#               for samp4 in os.listdir(os.path.join(prt_fol_pth, samp3)):\n","#                 #open images and resize\n","#                 img = np.array(os.path.join(prt_fol_pth, ech_samp, samp1))\n","#                 img2 = np.array(os.path.join(prt_fol_pth, samp3, samp4))\n","\n","#                 #concate images together as flatten\n","#                 out = np.array([0]) #output\n","#                 con_img = np.c_[img,img2]\n","#                 img_d = np.copy(np.c_[con_img,out])\n","\n","#                 #add img to dataset\n","#                 nw_dset = np.r_[nw_dset,img_d] \n","\n","#       self.rel_dset = nw_dset\n","\n","#   def shuffle_reldset(self):\n","#     #splitting dataset into train,remaining\n","#     split = StratifiedShuffleSplit(test_size=0.2)\n","#     X = self.rel_dset[:,:-1]\n","#     y = np.float32(self.rel_dset[:,-1:])\n","\n","#     for trn_idx, tst_idx in split.split(X,y):\n","#         x_trn, x_tst = X[trn_idx], X[tst_idx]\n","#         y_trn, y_tst = y[trn_idx], y[tst_idx]\n","\n","#     self.train_X, self.train_y = (x_trn, y_trn)\n","#     self.test_X, self.test_y = (x_tst, y_tst)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lu4My8Pd6wU9","colab_type":"code","colab":{}},"source":["#encod = OneHotEncoder(categories='auto')\n","#y_ = encod.fit_transform(y).toarray()\n","\n","#splitting dataset into train,remaining\n","#split = StratifiedShuffleSplit(test_size=0.2)\n","#\n","#for trn_idx, tst_idx in split.split(X,y):\n","#    x_trn, x_tst = X[trn_idx], X[tst_idx]\n","#    y_trn, y_tst = y[trn_idx], y[tst_idx]\n","\n","#encod = OneHotEncoder(categories='auto')\n","#y_trn= encod.fit_transform(y_trn).toarray()\n","#y_tst= encod.fit_transform(y_tst).toarray()\n","\n","#train_target = tch.tensor(y_trn.astype(np.float32))\n","#train =        tch.tensor(x_trn.astype(np.float32)) \n","#\n","#test_target =  tch.tensor(y_tst.astype(np.float32)) \n","#test =         tch.tensor(x_tst.astype(np.float32))\n","\n","#batch_size = 6\n","#train_tensor = tch.utils.data.TensorDataset(train, train_target) \n","#train_loader = tch.utils.data.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)\n","#\n","#val_tensor =  tch.utils.data.TensorDataset(test, test_target) \n","#val_loader =  tch.utils.data.DataLoader(dataset = val_tensor, batch_size = batch_size, shuffle = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"igSuSw1n0iGt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJJUpHsy0iDx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5Y-ECs10iAS","colab_type":"code","colab":{}},"source":["#load the images with their references\n","  def load_paths(self, X, y):\n","    self.loaded += len(X)\n","    siz = 224\n","    #prt_fol = os.listdir(prt_fol_pth)\n","    nw_dset = np.empty((0,224,224,6))\n","    target = np.empty((0,1))\n","    trans = transforms.Compose([ transforms.Resize((224,224)),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])\n","\n","    \n","    for x_,y_ in zip(X,y):\n","        #open images and resize\n","        img = Image.open(x_[0])\n","        img = trans(img).numpy().transpose((1, 2, 0))\n","\n","        img2 = Image.open(x_[1])\n","        img2 = trans(img2).numpy().transpose((1, 2, 0))\n","        \n","        #one hot encode target\n","        out = np.array([y_]) #output\n","\n","        #concate images together as flatten\n","        con_img = np.expand_dims(np.c_[img,img2],0)\n","        img_d = np.copy(con_img)\n","\n","        #add img to dataset\n","        nw_dset = np.r_[nw_dset,img_d]\n","        target = np.r_[target,out]    \n","    target = encod.transform(target)\n","    return tch.tensor(nw_dset.astype(np.float32)), tch.tensor(target.astype(np.float32))\n","\n","\n","# reset the state of the dataloader and shuffle the image references\n","  def reset(self):\n","\n","    #set len of dataset and the loaded dataset\n","    self.len_relset = 0\n","    self.loaded = 0\n","\n","    #shuttle the dataset\n","    self.X, self.y = self.shuffle_reldset(X=self.X,y=self.y,split_d=False, test_s=0.5) \n","\n","  def __loaded__(self):\n","    return self.loaded\n","\n","\n","  # iteration method\n","  def __iter__(self):\n","    return self \n","\n","  #get next image\n","  def __next__(self):\n","    self.len_relset += self.batch_size\n","    \n","    if ((self.len_relset-1)== self.X.shape[0]):\n","      self.reset()\n","      raise StopIteration\n","    return self.load_paths(self.X[self.len_relset:self.len_relset+self.batch_size], self.y[self.len_relset:self.len_relset+self.batch_size])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TBtmDjWy0h9a","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSPlNg070h6l","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PGKfmOcw0h3c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTTEjsv40h0A","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IGWPyhmj0hxE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOIw87970ht-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJT2v2ib0hqj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TjIRSG_-0hnv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dbgema0H0hkz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"icSbzxUU0hhN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FR1-o9ec0hao","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZ4b5Bwz4ng_","colab_type":"code","colab":{}},"source":["model.predict(data_x[100:150,:,:,:])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQJljwfb-qzD","colab_type":"code","colab":{}},"source":["2.21848991e-02"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DO9__eeF6D8w","colab_type":"code","colab":{}},"source":["data_y[100:150]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnZMEhZsBFX9","colab_type":"code","colab":{}},"source":["#Testing the model\n","features = tch.tensor(X.astype(np.float32))\n","targets = tch.tensor(y.astype(np.float32)) \n","\n","features[0:10,:,:,:].shape\n","#loading cnn\n","# resnet = torch.load('trmodel.pt')\n","# cnn = resnet['model_arc']\n","# cnn.load_state_dict(resnet['state_dict'])\n","\n","# #loading neural net\n","# nw_nt = torch.load('itmodel1.pt')\n","# neural_network = nw_nt['model_arc']\n","# neural_network.load_state_dict(nw_nt['state_dict'])\n","\n","# #Using class\n","# Final_model = train_model(cnn=cnn, model=neural_network)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HfaP3xzX3e8u","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XZnTjdw9B3l","colab_type":"code","colab":{}},"source":["# np.expand_dims(np.c_[img,img2],0).shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HiIISUsRlMe9","colab_type":"code","colab":{}},"source":["# trans = transforms.Compose([ transforms.Resize((224,224)),\n","#                                       transforms.ToTensor(),\n","#                                       transforms.Normalize([0.485, 0.456, 0.406],\n","#                                                            [0.229, 0.224, 0.225])])\n","# img = Image.open('Pictures/wonder/DSC_0261.JPG')\n","# img2 = Image.open('Pictures/blaq/IMG_20190428_235929.jpg')\n","# img = trans(img)\n","# img2 = trans(img2)\n","# plt.imshow(np.c_[img,img2][:,:,:224].reshape(224,224,3))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"taZ2fRUeBFVV","colab_type":"code","colab":{}},"source":["#predicting\n","accuracy_score(model.predict(train[:1,:,:,:]).numpy(),train_target[:1, 1:])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xlt8H2tD1tbI","colab_type":"code","colab":{}},"source":["train_target[0:10, 1:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1e5PFWjrBFSf","colab_type":"code","colab":{}},"source":["Final_model.predict(feature[80:85,:,:,:]).cpu().numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMWkVidDBFPe","colab_type":"code","colab":{}},"source":["targets[80:85].numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"esKoyu_fBFMF","colab_type":"code","colab":{}},"source":["targets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wT2F6A-qBFIq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zaTZpCsQBFFK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DOKASP2BE9-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gu-3xJL88PBG","colab_type":"code","colab":{}},"source":["_1_hidtrain.predict(data=test[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXoEDrgZ8O-c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K4wrWYaW8O66","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkGXePWU8O3w","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hBTa5g58O0x","colab_type":"code","colab":{}},"source":["e"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sfkVqZd88Owk","colab_type":"code","colab":{}},"source":["z"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXYARZzx8OsO","colab_type":"code","colab":{}},"source":["class train_model:\n","  \n","  def __init__(self,cnn = None,model = None, lr=0.01):\n","    self.cnn = cnn\n","    self.model = model\n","    self.criterion = None\n","    self.optimizer = None\n","    self.weights = None\n","    self.y_scores_train = []\n","    self.y_scores_test = []\n","    self.train_loss = []\n","    self.test_loss = []\n","    self.train_acc = []\n","    self.test_acc = []\n","    self.train_rec = []\n","    self.test_rec = []\n","    self.train_f1_scr = []\n","    self.test_f1_scr = []\n","    self.train_pre = []\n","    self.test_pre = []\n","    self.t_epch = 0\n","    self.loaded_tr = 0\n","    self.loaded_vl = 0\n","    \n","  def train(self,train_loader=None, valid_loader=None,criterion=None,optimizer=None,epochs=5,batch_size=[400,40],lst_val_scr=0):\n","    \n","    model = self.model\n","    cnn = self.cnn\n","    valid_rec_min = lst_val_scr\n","    train_on_gpu = True #tch.cuda.is_available()\n","    new_state = model.state_dict()\n","    self.t_epch += epochs\n","\n","    if len(batch_size) == 2:\n","      batch_s_t = batch_size[0]\n","      batch_s_v = batch_size[1]\n","    else:\n","      batch_s_t = batch_size[0]\n","      batch_s_v = batch_size[0]    \n","\n","    for epoch in range(epochs):\n","      # keep track of training and validation loss and scores\n","        train_loss    = 0.0\n","        test_loss    = 0.0\n","        train_acc     = 0.0\n","        train_pre     = 0.0\n","        train_rec     = 0.0\n","        train_f1_scr  = 0.0\n","        test_acc      = 0.0\n","        test_pre      = 0.0\n","        test_rec      = 0.0\n","        test_f1_scr   = 0.0\n","      \n","      ###################\n","      # train the model #\n","      ###################\n","        model.cuda()\n","        for data, target in train_loader:\n","            self.loaded_tr += len(data)\n","       \n","          # move tensors to GPU if CUDA is available\n","            if train_on_gpu: \n","                cnn.eval()\n","                model.train()\n","                data, target = data.cuda(), target.cuda()\n","            else:\n","                cnn.eval()\n","                model.cpu()\n","                model.train()\n","                data, target = data.cpu(), target.cpu()\n","     \n","          # clear the gradients of all optimized variables\n","            optimizer.zero_grad()\n","     \n","            data = data.cpu()\n","            img = data[:,:,:,:3]\n","            img2 = data[:,:,:,3:]\n","            print(f'in Train-->({self.loaded_tr}) \\n img1 --> {img.shape} \\n img2 --> {img2.shape}')\n","            img = cnn(tch.from_numpy(img.numpy().transpose((0, 3, 1, 2))))\n","            img2 = cnn(tch.from_numpy(img2.numpy().transpose((0, 3, 1, 2))))\n","\n","            data = tch.cat((img,img2),1).cuda()\n","          \n","          \n","          \n","          # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(data)\n","            #print(f'output_train is {output} and target is {target}')\n","          # calculate the batch loss\n","            loss = criterion(output, target)                   \n","      \n","          # backward pass: compute gradient of the loss with respect to model parameters\n","            loss.backward()\n","      \n","          # perform a single optimization step (parameter update)\n","            optimizer.step()\n","       \n","          # update training loss\n","            train_loss     +=  loss.item()*data.size(0)\n","            train_acc      +=  accuracy_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            train_pre      +=  precision_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            train_rec      +=  recall_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            train_f1_scr   +=  f1_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            self.save_model()\n","        self.loaded_tr = 0\n","\n","\n","      ######################    \n","      # validate the model #\n","      ######################\n","        cnn.eval()\n","        model.eval()\n","     \n","        for data, target in valid_loader:\n","            self.loaded_vl += len(data)\n","          # move tensors to GPU if CUDA is available\n","            if train_on_gpu:\n","                data, target = data.cuda(), target.cuda()\n","                data = data.cpu()\n","                img = data[:,:,:,:3]\n","                img2 = data[:,:,:,3:]\n","                print(f'in val-->({self.loaded_vl}) \\n img1 --> {img.shape} \\n img2 --> {img2.shape}')\n","                img = cnn(tch.from_numpy(img.numpy().transpose((0, 3, 1, 2))))\n","                img2 = cnn(tch.from_numpy(img2.numpy().transpose((0, 3, 1, 2))))\n","\n","                data = tch.cat((img,img2),1).cuda()\n","                \n","          # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(data)\n","            #print(f'output_val is {output} and target is {target}')\n","          # calculate the batch loss\n","            loss = criterion(output, target)\n","                    \n","          # update average validation loss \n","            test_loss     += loss.item()*data.size(0)\n","            test_acc       += accuracy_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            test_pre       += precision_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            test_rec       +=  recall_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            test_f1_scr    +=  f1_score(target.cpu()[:,1:], output.cpu().topk(1)[1])\n","            \n","        self.loaded_vl = 0       \n","      # calculate average losses and scores\n","        train_loss = train_loss/round(len(train_loader.dataset)/batch_size)\n","        test_loss = test_loss/round(len(valid_loader.dataset)/batch_size)\n","      \n","        train_acc       =   1 if  train_acc/round(len(train_loader.dataset)/batch_s_t) > 1 else train_acc/round(len(train_loader.dataset)/batch_s_t)\n","\n","        train_pre       =   1 if train_pre/round(len(train_loader.dataset)/batch_s_t) > 1 else train_pre/round(len(train_loader.dataset)/batch_s_t)\n","\n","        train_rec       =   1 if train_rec/round(len(train_loader.dataset)/batch_s_t) > 1 else train_rec/round(len(train_loader.dataset)/batch_s_t)\n","                                     \n","        train_f1_scr    =   1 if train_f1_scr/round(len(train_loader.dataset)/batch_s_t) > 1 else train_f1_scr/round(len(train_loader.dataset)/batch_s_t)\n","\n","        test_acc        =   1 if test_acc/round(len(valid_loader.dataset)/batch_s_v) > 1 else test_acc/round(len(valid_loader.dataset)/batch_s_v)\n","\n","        test_pre        =   1 if test_pre/round(len(valid_loader.dataset)/batch_s_v) > 1 else test_pre/round(len(valid_loader.dataset)/batch_s_v)\n","  \n","        test_rec        =   1 if test_rec/round(len(valid_loader.dataset)/batch_s_v,5) > 1 else test_rec/round(len(valid_loader.dataset)/batch_s_v,5)\n","\n","        test_f1_scr    =   1 if test_f1_scr/round(len(valid_loader.dataset)/batch_s_v,5) > 1 else test_f1_scr/round(len(valid_loader.dataset)/batch_s_v,5) \n","\n","      \n","\n","            \n","      #append train scores\n","        self.train_loss.append(train_loss)\n","        self.train_acc.append(train_acc)\n","        self.train_rec.append(train_rec)\n","        self.train_f1_scr.append(train_f1_scr)\n","        self.train_pre.append(train_pre)\n","        \n","      #append test scores\n","        self.test_loss.append(test_loss)\n","        self.test_acc.append(test_acc)\n","        self.test_rec.append(test_rec)\n","        self.test_f1_scr.append(test_f1_scr)\n","        self.test_pre.append(test_pre)\n","        \n","      # print training/validation statistics \n","        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} '.format(epoch, train_loss, test_loss))\n","      \n","        print('train Accuracy score : {:.6f} \\ttrain Precision Score: {:.6f} \\ttrain Recall Score: {:.6f}\\ttrain f1 Score: {:.6f}'.format(train_acc, train_pre, train_rec, train_f1_scr))\n","      \n","        print('test Accuracy score : {:.6f} \\ttest Precision Score: {:.6f} \\ttest Recall Score: {:.6f}\\ttest f1 Score: {:.6f}'.format(test_acc, test_pre, test_rec, test_f1_scr))\n","        self.model = model\n","        self.cnn = cnn\n","        self.save_model()\n","      # save model if validation loss has decreased\n","        if test_rec > valid_rec_min:\n","            print('test recall increased ({:.6f} --> {:.6f}).  Saving model ...\\n\\n'.format(valid_rec_min,test_rec))\n","            \n","            #Save State_dict\n","            fc_model_info = {'model_arc'  : model,\n","                             'state_dict' : model.state_dict()}\n","            \n","            cnn_model_info = {'model_arc'  : cnn,\n","                              'state_dict' : cnn.state_dict()}\n","            \n","\n","            torch.save(fc_model_info, 'fcmodel_deploy0.pt')\n","            torch.save(cnn_model_info, 'cnnmodel_deploy0.pt')\n","            valid_rec_min = test_rec\n","\n","  def predict(self,data):\n","    model = self.model\n","    model.cpu().eval()\n","    cnn = self.cnn\n","    \n","    cnn.cpu().eval()\n","    data = data.cpu()\n","    img = data[:,:,:,:3]\n","    img2 = data[:,:,:,3:]\n","      f\n","    img = cnn(tch.from_numpy(img.numpy().transpose((0, 3, 1, 2))))\n","    img2 = cnn(tch.from_numpy(img2.numpy().transpose((0, 3, 1, 2))))\n","\n","    data = tch.cat((img,img2),1)\n","\n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    output = model(data)\n","    \n","    return output.cpu().topk(1)[1].detach().numpy()\n","  \n","  \n","  def save_model(self):\n","    model = self.model\n","    cnn = self.cnn\n","\n","      #Save State_dict\n","    fc_model_info = {'model_arc'  : model,\n","                     'state_dict' : model.state_dict()}\n","\n","    cnn_model_info = {'model_arc'  : cnn,\n","                      'state_dict' : cnn.state_dict()}\n","\n","    torch.save(fc_model_info, 'fcmodel_gen0.pt')\n","    torch.save(cnn_model_info, 'cnnmodel_gen0.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9G-6GKJq8Omi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQWUJQ3YgB2o","colab_type":"code","colab":{}},"source":["# modelk = models.resnet152(pretrained=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cw81SD0Ai7u","colab_type":"code","colab":{}},"source":["# modelg.fc = nn.Identity()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KTIApSZ9x48M","colab_type":"code","colab":{}},"source":["# #Save State_dict\n","# model_info = {'model_arc'  : modelg,\n","#              'state_dict' : modelg.state_dict()}\n","\n","# torch.save(model_info, 'trmodel.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIupErKGyUls","colab_type":"code","colab":{}},"source":["# Load Saved model arch\n","vgg = torch.load('trmodel.pt')\n","model = vgg['model_arc']\n","model.load_state_dict(vgg['state_dict'])\n","for param in model.parameters():\n","  param.requires_grad = False\n","  \n","  \n","imgt = model(img)\n","img2t = model(img2)\n","tch.cat((imgt,img2t),1).shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpWX1Z5CzpKO","colab_type":"code","colab":{}},"source":["#Building the model\n","# neural network architecture\n","fc = nn.Sequential(OrderedDict([ \n","                                   (\"input\", nn.Linear(4096, 1000)),\n","                                   (\"act_1\", nn.ReLU()),\n","                                   (\"hidd\", nn.Linear(1000, 2)),\n","                                   (\"out\", nn.Softmax(dim=1))\n","                               ]))\n","mod = tch.load('fcmodel_gen0.pt')\n","fc = mod['model_arc']\n","fc.load_state_dict(mod['state_dict'])\n","\n","resnet = torch.load('cnnmodel_gen0.pt')\n","cnn = resnet['model_arc']\n","cnn.load_state_dict(resnet['state_dict'])\n","\n","# for param in cnn.parameters():\n","#   param.requires_grad = True\n","  \n","# cnn = models.resnet50(pretrained=True)\n","ct = 0\n","for child in cnn.children():\n","  ct += 1\n","  if ct < 8:\n","      for param in child.parameters():\n","          param.requires_grad = False\n","\n"],"execution_count":0,"outputs":[]}]}